---
title: "LECTURE 8: multiple comparisons"
subtitle: "FANR 6750 (Experimental design)"
author: "<br/><br/><br/>Fall 2024"
output:
  xaringan::moon_reader:
    css: ["default", "FANR6750.css", "FANR6750-fonts.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, echo = FALSE, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center', warning=FALSE, message=FALSE, fig.retina = 2)
source(here::here("R/zzz.R"))
library(emo)
library(FANR6750)
library(dplyr)
library(kableExtra)
# library(gganimate)
```

# motivation

<br/>

> Following a significant *F*-test, the next step is to determine which means differ  

<br/>

--
> If all group means are to be compared, then we should correct for multiple testing

<br/>

--

> That is, conducting many tests increases the probability of finding one that is significant, even if it is not

---

```{r echo = FALSE, out.height="600px"}
knitr::include_graphics("https://imgs.xkcd.com/comics/significant.png")
```

---
class: inverse

# outline


#### 1) Pairwise *t*-tests

<br/> 
--

#### 2) Tukey's HSD test

<br/> 
--

#### 3) *a priori* contrasts

<br/> 

---
# motivating example

#### Aphids are a major crop pest and farmers are interested which brands of pesticide have the biggest influence on crop yield

#### The data:

```{r echo = TRUE, fig.height=3.5, fig.width=3.5}
data("pesticidedata")

ggplot(pesticidedata, aes(x = Brand, y = Yield)) + 
  geom_boxplot()
```

---
# motivating example

.small-code[
```{r echo = TRUE}
fit.lm <- lm(Yield ~ Brand, data = pesticidedata)
summary(fit.lm)
```
]

---
class: center, inverse, middle

## PAIRWISE *t*-TEST

---
## PAIRWISE *t*-TEST

<br/>

#### One can always fall back on pairwise, two-sample *t*-tests (or linear models)


```{r echo = TRUE}
pairwise.t.test(pesticidedata$Yield, pesticidedata$Brand, p.adjust.method = "none")
```

---
## PAIRWISE *t*-TEST

One can always fall back on pairwise, two-sample *t*-tests (or linear models)...BUT

--

Running multiple tests increases the probability of finding one that is significant, even if it is not (remember the jellybeans!)

```{r fig.height = 3.5, fig.width=5}
n <- 1:100
p <- 1 - (1 - 0.05)^n
p_df <- data.frame(n.test = n,p=p)
ggplot(p_df, aes(x = n.test, y = p)) + 
  geom_path() +
  scale_x_continuous("Number of tests") +
  scale_y_continuous("Experiment-wise error rate") +
  theme(axis.title.y = element_text(size = 16))
```

--

One common way to deal with multiple comparisons is to do pairwise *t*-tests but *adjust* the *p*-values of each test

- Essentially, the adjustments make it harder to reject the null hypothesis, thereby making the tests more conservative

---
# bonferroni adjustment

#### One of the most common adjustments is the *Bonferroni* correction

- Multiply each *p*-value by the number of tests  

- If this results in *p* > 1, set *p* to 1  

--

.small-code[
```{r echo = TRUE}
pairwise.t.test(pesticidedata$Yield, pesticidedata$Brand, p.adjust.method = "bonferroni")
```
]

---
class: inverse

# reflection

#### At first, it can be confusing when a *p*-value is significant in one case (e.g., unadjusted) but not significant in another (e.g., Bonferroni)

- (especially if you're a grad student working on your thesis and you really *want* significant results)

--

#### If you find yourself in this situation, take a step back and think about a few things:

--

- What does the p-value measure? What is the risk when rejecting the null hypothesis? 

--

- When is falsely rejecting the null hypothesis (Type I error) most likely?

--

- What is so special about $\alpha = 0.05$?

---
class: center, middle, inverse

# tukey's hsd test

---
# john tukey

<br/>

```{r tukey, echo = FALSE, out.height="300px", out.width="246px"}
knitr::include_graphics("fig/John_Tukey.jpeg")
```

<br/>

> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data

---
# tukey's hsd test

<br/>

#### According to Tukey's Honestly Significant Difference test, two means ( $\bar{y}_i$ and $\bar{y}_j$) are different if:

$$\large |\bar{y}_i - \bar{y}_j | \geq  q_{1- \alpha,a,a(n-1)}\sqrt{\frac{MSW}{n}}$$

<br/>

where $q$ comes from the "Studentized Range Distribution"(see `qtukey` in `R`). MSW = mean squared error from the ANOVA table


---
# example

```{r echo = TRUE}
fit.aov <- aov(Yield ~ Brand, data = pesticidedata)
TukeyHSD(fit.aov)
```

---
# *a posteriori* comparisons

--

- Bonferonni and Tukey's HSD are the most commonly used types of *a posteriori* comparisons - comparing all possible pairwise combinations only *after* a significant F-test

--

- There are many other types of *a posteriori* comparison, e.g. Fisher's LSD (see `?p.adjust` for even more)

--

- *A posteriori* comparisons decrease the risk of Type I error (but increase the risk of Type II error)

--

- By forcing the researcher to correct for all possible combinations, *a posteriori* comparisons often overly conservative 

--

- A better approach in many situations is to use *a priori* **contrasts**

---
class:center, inverse, middle

# *a priori* contrasts

---
# mussel size

```{r echo = FALSE}
library(dplyr)
data("musseldata")

cs <- dplyr::mutate(musseldata, ID = rep(1:5, 4)) %>%
        tidyr::pivot_wider(names_from = Watershed, values_from = Length) %>%
         select(-ID)

cs %>%
  kable("html", align = 'c') %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = TRUE) %>%
  add_header_above(c("Watershed" = 4))
```

--
- Chattooga and Keowee are more forested  

- Coneross and Twelvemile are more agricultural

---
# anova results


.small-code[
```{r echo = TRUE}
fit.mussel <- lm(Length ~ Watershed, data = musseldata)
summary(fit.mussel)
```
]

---
# pairwise comparisons


.small-code[
```{r echo = TRUE}
pairwise.t.test(musseldata$Length, musseldata$Watershed, p.adjust.method = "bonferroni")
```
]

---
# hypotheses

#### Instead of comparing all possible combinations, what if we are only interested in some specific comparisons?

1) Do the agricultural watersheds differ from one another?

2) Do the forested watersheds differ from one another?

--

#### Also, what if we are interested in *combinations* of treatments? 

3) Do mussels from forested watersheds differ from agricultural watersheds?

--

#### What are the advantages of focusing only on these specific questions?

---
# hypotheses as contrasts

#### Hypotheses

```{r echo = FALSE}
h0 <- data.frame(col1 = c("1", "2", "3"),
                 Comparison = c("Forested vs agricultural", 
                                "Twelvemile vs Coneross",
                                "Chattooga vs Keowee"),
                 H = c('\\(\\frac{\\mu_T + \\mu_{Co}}{2} - \\frac{\\mu_{Ch} + \\mu_K}{2}=0\\)',
                       '\\(\\mu_{T} - \\mu_{Ch} = 0\\)',
                       '\\(\\mu_{Ch} - \\mu_{K} = 0\\)'))

h0 %>%
    kable(align = c("l", "l", "c"), col.names = c("", "Comparisons", "H0 to test"), 
          booktabs = TRUE, escape = FALSE, format = "html") %>%
    kable_styling(bootstrap_options = c("condensed"), 
                full_width = FALSE, font_size = 16) 
```

--

#### Linear combinations

```{r echo = FALSE}
lc <- data.frame(col1 = c("1", "2", "3"),
                 H = c('\\((1/2)\\mu_T - (1/2)\\mu_{Ch} - (1/2)\\mu_{K} + (1/2)\\mu_{Co}\\)',
                       '\\((1)\\mu_T + (0)\\mu_{Ch} + (0)\\mu_{K} - (1)\\mu_{Co}\\)',
                       '\\((0)\\mu_T + (1)\\mu_{Ch} - (1)\\mu_K + (0)\\mu_{Co}\\)'))

lc %>%
    kable(align = c("c", "l"), col.names = NULL, 
          booktabs = TRUE, escape = FALSE, format = "html") %>%
    kable_styling(bootstrap_options = c("condensed"), 
                full_width = FALSE, font_size = 16) 
```

---
# are these contrasts orthogonal?

A set of linear combinations is called a set of orthogonal contrasts if the following conditions hold for all pairs of linear combinations:  

<br/>

--
Given

$$\Large L_1 = a_1\mu_1 + a_2\mu_2 + ... + a_a\mu_a$$
--

and

$$\Large L_2 = b_1\mu_1 + b_2\mu_2 +...+ b_a\mu_a$$
--

then $L_1$ and $L_2$ are orthogonal if:

$$\large \sum_i a_i=0;\;\; \sum_i b_i=0; \;\;and \; \sum_i a_ib_i=0$$

---
# back to the saw data

Returning to the question: "Does mussel size differ among forested and agricultural watersheds?":

$$\large H_{0_1} = \frac{\mu_T + \mu_{Co}}{2} - \frac{\mu_{Ch} + \mu_{K}}{2} = 0$$

--
Multiplying through by 2 gives:

$$\large H_{0_1} = (\mu_{T} + \mu_{Co}) - (\mu_{Ch} + \mu_K) = 0$$

--
Which can be written as:
$$\large L1 = (1)\mu_T + (-1)\mu_{Ch} + (-1)\mu_K + (1)\mu_{Co}$$
where the coefficients are $a_1 = 1$, $a_2 = -1$, $a_3 = -1$, and $a_4 = 1$

--

> Note that it's easier to work with coefficients that are integers rather than fractions

---
# are the contrasts orthogonal?

--

#### Does each set of coefficients sum to 0?

- $\large L_1$: $\large \sum_i a = 1 - 1 - 1 + 1 = 0$


- $\large L_2$: $\large \sum_i a  = 1 + 0 + 0 - 1 = 0$


- $\large L_3$: $\large \sum_i a  = 0 + 1 - 1 + 0 = 0$

--

#### Do the products of pairs of coefficients sum to 0?

- For $\large L_1$ and $\large L_2$: $\large (1)(1) + (-1)(0) + (-1)(0) + (1)(-1) = 0$

- For $\large L_1$ and $\large L_3$: $\large (1)(0) + (-1)(1) + (-1)(-1) + (1)(0) = 0$

- For $\large L_2$ and $\large L_3$: $\large (1)(0) + (0)(1) + (0)(-1) + (-1)(0) = 0$

---
# testing the null hypotheses

To obtain the sums of squares for each contrast, we use the general formula:

$$\large SS_L =\frac{(\sum_i a_i T_i)^2}{n \sum_i a_i^2}$$

where $\large  T_i$ is the sum of observations in group $\large  i$, and $\large  a_i$ is the corresponding coefficient for group $\large  i$  

--

For thefirst hypothesis we have:

$$ \large SS_{L_1} = \frac{(66-107-121+77)^2}{5(1 + 1 + 1 + 1)} = 361.2$$

---
# sums of squares for each contrast

For the second hypothesis we have: $\large L_2 = \mu_T + 0 + 0 - \mu_{Co}$ with coefficients $\large a_i = (1, 0, 0,-1)$

$$\large SS_{L_2} = \frac{(66 +0 +0 - 77)^2}{5(1 + 0 + 0 + 1)} = 12.1$$

--

For the third hypothesis we have: $\large L_3 = 0 + \mu_B - \mu_C + 0$ with coefficients $\large a_i = (0, 1,-1, 0)$

$$\large SS_{L_3} = \frac{(0 + 107 - 121 + 0)^2}{5(0 + 1 + 1 + 0)} = 19.6$$
---
# expanded anova table

For each contrast, each SS is divided by 1 d.f., and then divided by MSW

```{r echo = FALSE}
cs <- data.frame(Source = c("Among watersheds", "F vs Ag ", "T vs Co", "Ch vs K", "Within"),
                 df = c("3","1", "1", "1", "16"),
                 SS = c(393, 361, 12, 20, 216),
                 MS = c(131, 361, 12, 20, 13.5),
                 F = c(9.70, 26.76, 0.90, 1.45, NA),
                 p = c("0.007", "9e-5", "0.36", "0.25", NA))
options(knitr.kable.NA = '') # don't print NA's in table
cs %>%
    kable(align = c("r", "c", "c", "c", "c", "c"), 
          booktabs = TRUE, escape = FALSE, format = "html") %>%
    kable_styling(bootstrap_options = c("condensed"), 
                full_width = FALSE, font_size = 16) 
```

--

Notice that the Sums of Squares are partitioned according to hypotheses we are interested in, unlike in multiple comparison procedures.

---
# *a priori* contrasts

- Orthogonal contrasts are more powerful than multiple comparison procedures  

--

- They also require more thought and preparation (good things!)  

--

- There can be only $a - 1$ comparisons  

--

- If the contrasts are not orthogonal, they can't be used to fully partition the Sums of Squares among groups  

--

- If the comparisons really represent more than 1 treatment variable, it will be better to use a factorial design. More on that later

---
# looking ahead

<br/>

### **Next time**: Multiple regression

<br/>

### **Reading**: [Fieberg chp. 3.2-3.5](https://statistics4ecologists-v1.netlify.app/matrixreg#introduction-to-multiple-regression)

