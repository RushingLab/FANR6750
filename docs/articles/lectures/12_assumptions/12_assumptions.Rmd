---
title: "LECTURE 12: evaluating assumptions"
subtitle: "FANR 6750 (Experimental design)"
author: "<br/><br/><br/>Fall 2025"
output:
  xaringan::moon_reader:
    css: ["default", "FANR6750.css", "FANR6750-fonts.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, echo = FALSE, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center', warning=FALSE, message=FALSE, fig.retina = 2)
source(here::here("R/zzz.R"))
# library(emo)
library(FANR6750)
library(dplyr)
library(kableExtra)
# library(gganimate)
```

class: inverse

# outline

#### 1) Review of linear model assumptions

<br/>  
--

#### 2) Evaulating assumptions

<br/> 
--

#### 3) Robustness to assumption violations

<br/> 

--

#### 4) Multicolinearity


---
# assumptions

#### **EVERY** model has assumptions

--

- Assumptions are necessary to simplify real world to workable model

--

- If your data violate the assumptions of your model, inferences *may* be invalid

--

- **Always** know (and test) the assumptions of your model

---
# linear model assumptions

</br>

$$\Large y_i = \beta_0 + \beta_1 x_i + \epsilon_i$$

$$\Large \epsilon_i \sim normal(0, \sigma)$$


</br>

--

1) **Linearity**: The relationship between $x$ and $y$ is linear

--

2) **Normality**: The residuals are normally distributed

--

3) **Homogeneity**: The residuals have a constant variance at every level of $x$

--

4) **Independence**: The residuals are independent (i.e., uncorrelated with each other)

---
# evaluating assumptions

Evaluating whether your data violate the linear model assumptions relies heavily on **residuals** 

- Residuals are the difference between the observed and predicted response value of each observation

- $r_i = (y_i - \hat{y}_i)$

--

Plotting the residuals vs the predicted values provides a visual assessment of the linearity assumptions

--

Plotting the residuals vs the predicted values or $X$ provides a visual assessment of the variance assumption

--

Plotting a Q-Q plot or histogram of the residuals provides visual assessments of the normality assumption

---
# evaluating assumptions

Fortunately, multiple `R` packages include functions for making diagnostic plots from a fitted `lm` object

.vsmall-code[
```{r echo = TRUE, fig.height=5, fig.width=8}
library(performance)
data("biomassdata")
fm1 <- lm(biomass ~ elevation + rainfall, data = biomassdata)
check_model(fm1, check = c("linearity", "homogeneity", "qq", "normality"))
```
]

---
# linearity

Deviations from linearity will appear as patterns in the residual plot

.pull-left[
```{r fig.height=5, fig.width=6}
fm1_df <- data.frame(Residuals = fm1$residuals,
                     Fitted = fm1$fitted.values)
ggplot(fm1_df, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "grey40", linetype = "dashed") +
  stat_smooth()
```
]

.pull-right[
```{r fig.height=5, fig.width=6}
x <- runif(50, 0, 10)
ey <- x^1.5
y <- rnorm(50, ey, 1)
fm2 <- lm(y ~ x)
fm2_df <- data.frame(Residuals = fm2$residuals,
                     Fitted = fm2$fitted.values)
ggplot(fm2_df, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "grey40", linetype = "dashed") +
  stat_smooth()
```
]

---
# homogeneity of variance

Heteroscedasticity will appear as patterns (often funnel-shaped) in the residual plot

.pull-left[
```{r fig.height=5, fig.width=6}
fm1_df2 <- data.frame(Residuals = fm1$residuals,
                     Fitted = fm1$fitted.values)
ggplot(fm1_df2, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "grey40", linetype = "dashed") +
  stat_smooth()
```
]

.pull-right[
```{r fig.height=5, fig.width=6}
x <- runif(50, 0, 10)
ey <- 2 + 1.5 * x
sig <- 0.25 * 0.75 * x
y <- rnorm(50, ey, sig)
fm3 <- lm(y ~ x)
fm3_df <- data.frame(Residuals = fm3$residuals,
                     Fitted = fm3$fitted.values)
ggplot(fm3_df, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "grey40", linetype = "dashed") +
  stat_smooth()
```
]


---
# homogeneity of variance

Heteroscedasticity can also be assessed by plotting the square root of residuals. Violations will appear as increasing or decreasing trends

.pull-left[
```{r fig.height=5, fig.width=6}
fm1_r <- sqrt(abs(fm1$residuals/sd(fm1$residuals)))
fm1_df2 <- data.frame(Residuals = fm1_r,
                     Fitted = fm1$fitted.values)
ggplot(fm1_df2, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "grey40", linetype = "dashed") +
  stat_smooth() +
  scale_y_continuous("sqrt(|stn. r|)")
```
]

.pull-right[
```{r fig.height=5, fig.width=6}
fm3_r <- sqrt(abs(fm3$residuals/sd(fm3$residuals)))
fm3_df2 <- data.frame(Residuals = fm3_r,
                     Fitted = fm3$fitted.values)
ggplot(fm3_df2, aes(x = Fitted, y = Residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "grey40", linetype = "dashed") +
  stat_smooth() +
  scale_y_continuous("sqrt(|stn. r|)")
```
]

---
# normality

Normality is usually assessed using *quantile-quantile* (Q-Q) plots, which plots the observed quantiles of the residuals vs. the expected quantiles of normally distributed data 

.pull-left[
```{r fig.height=5, fig.width=6}
ggplot(biomassdata, aes(sample = biomass)) +
  stat_qq() +
  stat_qq_line() +
  scale_y_continuous("Sample quantiles") +
  scale_x_continuous("Standard normal quantiles")
```
]

.pull-right[
```{r fig.height=5, fig.width=6}
q_df <- data.frame(x = runif(60),
                   eps = rlnorm(60)) %>%
  mutate(ey = 3.2 + 1.2 * x,
         y = ey + eps)

ggplot(q_df, aes(sample = y)) +
  stat_qq() +
  stat_qq_line() +
  scale_y_continuous("Sample quantiles") +
  scale_x_continuous("Standard normal quantiles")
```
]

--

Large deviations from the line indicate deviations from normality


---
# evaluating models with factors

Because all of the models we have seen so far this semester are linear models, they all share the same assumptions

--

Testing assumptions of models with factors (*t*-test, ANOVA) is therefore no different than testing assumptions of models with continuous predictors

--

.vsmall-code[
```{r echo = TRUE, fig.height=3, fig.width=6}
data("tunadata")
fm2 <- lm(growth ~ status, data = tunadata)
```
]

```{r fig.height = 3.5, fig.width=7.5}
qq <- ggplot(tunadata, aes(sample = growth)) +
  stat_qq() +
  stat_qq_line() +
  scale_y_continuous("Sample quantiles") +
  scale_x_continuous("Standard normal quantiles")

fm2_df <- data.frame(Residuals = sqrt(abs(fm2$residuals/sd(fm2$residuals))),
                     Fitted = fm2$fitted.values,
                     X = tunadata$status)
h <- ggplot(fm2_df, aes(x = X, y = Residuals)) +
  geom_boxplot() +
  stat_smooth(method = "lm") +
  scale_x_discrete("Status") +
  scale_y_continuous("sqrt(|stn. r|)")

cowplot::plot_grid(h, qq, nrow = 1)
```

---
# null hypothesis testing

It is also possible to "test" whether assumptions are met:

.vsmall-code[
```{r echo = TRUE, fig.height=3, fig.width=6}
check_normality(fm1)
check_heteroscedasticity(fm1)
```
]

where the null hypothesis is that the data don't violate the assumption being test (so $p>0.05$ is good)

--

However, remember that the assumptions are about the population, not the sample

--

- samples can deviate from assumptions, even if they are met for the population

--

- deviations are more likely for small sample sizes

--

- there is always some judgement necessary when testing assumptions

--

We will explore some of these tests in lab

---
# independence

Non-independence of residuals is more difficult to test but is often related to un-modeled structure in the data

- points close in space/time tend to be more alike than distance points

- observations within "groups" (e.g., males/females, plots, growth chamber, lakes) tend to be more alike than individuals from other groups

--

Often, non-independence can be judged based on knowledge of the sampling design/system

- sometimes can be seen as "clustering" in residual plots

```{r fig.width = 4, fig.height=2.5}
x <- rnorm(50)
group <- sample(1:5, 50, replace = TRUE)
nu <- c(-5, -2, 0, 2, 5)
ey <- 5  + nu[group] + (1.2) * x
y <- ey + rnorm(50, 0, 0.5)

fm <- lm(y ~ x)

df <- data.frame(x = x, y = y, r = fm$residuals, 
                 e = fm$fitted.values, Lake = as.factor(group))
ggplot(df, aes(x = e, y = r, color = Lake)) + 
  geom_point() +
  scale_x_continuous("Expected value") +
  scale_y_continuous("Residuals") +
  theme(legend.title = element_text())
```

---
# independence

```{r fig.width = 6, fig.height=4}
ggplot(df, aes(x = e, y = r, color = Lake)) + 
  geom_point() +
  scale_x_continuous("Expected value") +
  scale_y_continuous("Residuals") +
  theme(legend.title = element_text())
```

Sometimes, non-independence can be remedied by including relevant covariates in the model

- e.g. `lm(y ~ x + Lake)`

- we'll learn more about this and related approaches in a few weeks


---
# what happens when assumptions are violated?

One consequences of sampling is that our samples will likely depart from assumptions to some degree

--

So rather than asking:

> "Do my data violate the assumptions of my model?"

It can be useful to ask:

> "Do my data violate the assumptions of my model *enough to change my conclusions*?"

--

Fortunately, linear models are relatively robust to minor (or even moderate) departures from the assumptions

---
# what happens when assumptions are violated?

General rules of thumb:

--

- Minor assumption violations will not generally bias estimates of $\hat{\beta}_0$, $\hat{\beta}_1$, etc.

--

- For large sample sizes, Central Limit Theorem often ensures that residuals of many types of data are normally distributed (or at least pretty close)

--

- Standard errors (and therefore confidence intervals, p-values, etc) *will* be biased when assumptions are violated

--

- In general, violating assumptions results in standard errors that are too small. What does this do to p-values?


---
class:inverse, center, middle

# multicolinearity

---
# multicolinearity

One topic that often causes confusion when fitting multiple regression models is *correlated predictors* (aka multicolinearity)

--

Many sources suggest trying to avoid including highly correlated predictors in the same model

- correlation coefficients $>0.7$ are often considered too correlated 

--

However, linear models make no assumptions about correlations between predictor variables. So what is the problem?

---
# example

We are interested in the factors that govern the evolution of body size of our study species and hypothesize that body length will increase with latitude and decrease temperature. Using museum collections, we have body length measurements from 80 individuals collected at sites between 40 and 50 degrees latitude. We also have long-term temperature data from each collection location. 

---
# example

As expected, body length appears to vary as a function of both latitude and temperature:

```{r fig.width=8, fig.height = 4}
data("lengthdata")
p <- ggplot(lengthdata, aes(x = Latitude, y = Length)) +
  geom_point() +
  scale_y_continuous("Body length (mm)")
r <- ggplot(lengthdata, aes(x = Temperature, y = Length)) +
  geom_point() +
  scale_y_continuous("")

cowplot::plot_grid(p, r, nrow = 1)
```

---
# example

Fitting models to each covariate also appears to confirm our hypotheses:

.vsmall-code[
```{r echo = TRUE}
data("lengthdata")
```
]

.pull-left[
.vsmall-code[
```{r echo = TRUE}
fmL <- lm(Length ~ Latitude, data = lengthdata)
summary(fmL)
```
]
]

.pull-right[
.vsmall-code[
```{r echo = TRUE}
fmT <- lm(Length ~ Temperature, data = lengthdata)
summary(fmT)
```
]
]

---
# example

But when we fit a model with both covariates, our conclusions are quite different:

.vsmall-code[
```{r echo = TRUE}
fmLT <- lm(Length ~ Latitude + Temperature, data = lengthdata)
summary(fmLT)
```
]

---
# example

What happened? 

--

The first thing to recognize is that latitude and temperature are highly negatively correlated:

```{r echo = TRUE}
cor(lengthdata$Latitude, lengthdata$Temperature)
```

```{r fig.height = 3, fig.width=5}
ggplot(lengthdata, aes(x = Latitude, y = Temperature)) +geom_point()
```

--

So high latitudes tend to have larger individuals *and* lower temperatures

---
# multicolinearity

At first, the fact that our estimated slope coefficient for Latitude changes signs and our conclusions about significance change between the two models may seem problematic

- the estimated effects and p-values are sensitive to which model we choose

- it may even be tempting to focus on the uni-variate models since they both give us significant results

--

But is there really a problem? Not if we remember the purpose of multiple regression and what the coefficients are measuring

---
# multicolinearity

The model with only latitude is measuring whether body length changes with latitude. Clearly it does (same for temperature). 

--

But the multiple regression model is measuring the effect of latitude *after controlling for temperature*

- If we hold temperature constant (statistically), does body length change with latitude? Apparently not<sup>\*</sup>

.footnote[\*In this **made up** data set]

---
# multicolinearity

In the presence of highly correlated predictors, multiple regression models do exactly what we want them to do! 

--

Changes in the magnitude/sign/significance in different regression models are expected because the coefficients measure different relationships

--

Larger standard errors are also common but are also expected - multiple regression is a harder problem to solve so, for a given sample size, uncertainty is larger

--

In general, do not automatically exclude correlated predictors just because they are correlated

- Ideally, variables should be included in the model because you have an *a priori* hypothesis about their effect or because they are needed to [control for confounding variation](https://statistics4ecologists-v3.netlify.app/07-causalnetworks)

- If parameter estimates are unreliable, you may need to use a more simple model (or gather more data)




---
# looking ahead

<br/>

### **Next time**: Model selection

<br/>

### **Reading**: Tredennick et al. 2021 (pdf will be posted on eLC for next week's paper discussion)

