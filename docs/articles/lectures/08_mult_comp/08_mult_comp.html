<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>LECTURE 8: multiple comparisons</title>
    <meta charset="utf-8" />
    <meta name="author" content="   Fall 2024" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="FANR6750.css" type="text/css" />
    <link rel="stylesheet" href="FANR6750-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# LECTURE 8: multiple comparisons
]
.subtitle[
## FANR 6750 (Experimental design)
]
.author[
### <br/><br/><br/>Fall 2024
]

---




# motivation

&lt;br/&gt;

&gt; Following a significant *F*-test, the next step is to determine which means differ  

&lt;br/&gt;

--
&gt; If all group means are to be compared, then we should correct for multiple testing

&lt;br/&gt;

--

&gt; That is, conducting many tests increases the probability of finding one that is significant, even if it is not

---

&lt;img src="https://imgs.xkcd.com/comics/significant.png" height="600px" style="display: block; margin: auto;" /&gt;

---
class: inverse

# outline


#### 1) Pairwise *t*-tests

&lt;br/&gt; 
--

#### 2) Tukey's HSD test

&lt;br/&gt; 
--

#### 3) *a priori* contrasts

&lt;br/&gt; 

---
# motivating example

#### Aphids are a major crop pest and farmers are interested which brands of pesticide have the biggest influence on crop yield

#### The data:


```r
data("pesticidedata")

ggplot(pesticidedata, aes(x = Brand, y = Yield)) + 
  geom_boxplot()
```

&lt;img src="08_mult_comp_files/figure-html/unnamed-chunk-2-1.png" width="252" style="display: block; margin: auto;" /&gt;

---
# motivating example

.small-code[

```r
fit.lm &lt;- lm(Yield ~ Brand, data = pesticidedata)
summary(fit.lm)
```

```
## 
## Call:
## lm(formula = Yield ~ Brand, data = pesticidedata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.932 -1.499  0.335  1.406  5.459 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   36.357      0.494   73.66  &lt; 2e-16 ***
## BrandA         3.142      0.698    4.50  1.9e-05 ***
## BrandB         3.940      0.698    5.65  1.7e-07 ***
## BrandC         5.616      0.698    8.05  2.3e-12 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.47 on 96 degrees of freedom
## Multiple R-squared:  0.416,	Adjusted R-squared:  0.397 
## F-statistic: 22.7 on 3 and 96 DF,  p-value: 3.29e-11
```
]

---
class: center, inverse, middle

## PAIRWISE *t*-TEST

---
## PAIRWISE *t*-TEST

&lt;br/&gt;

#### One can always fall back on pairwise, two-sample *t*-tests (or linear models)



```r
pairwise.t.test(pesticidedata$Yield, pesticidedata$Brand, p.adjust.method = "none")
```

```
## 
## 	Pairwise comparisons using t tests with pooled SD 
## 
## data:  pesticidedata$Yield and pesticidedata$Brand 
## 
##   Control A     B   
## A 2e-05   -     -   
## B 2e-07   0.26  -   
## C 2e-12   6e-04 0.02
## 
## P value adjustment method: none
```

---
## PAIRWISE *t*-TEST

One can always fall back on pairwise, two-sample *t*-tests (or linear models)...BUT

--

Running multiple tests increases the probability of finding one that is significant, even if it is not (remember the jellybeans!)

&lt;img src="08_mult_comp_files/figure-html/unnamed-chunk-5-1.png" width="360" style="display: block; margin: auto;" /&gt;

--

One common way to deal with multiple comparisons is to do pairwise *t*-tests but *adjust* the *p*-values of each test

- Essentially, the adjustments make it harder to reject the null hypothesis, thereby making the tests more conservative

---
# bonferroni adjustment

#### One of the most common adjustments is the *Bonferroni* correction

- Multiply each *p*-value by the number of tests  

- If this results in *p* &gt; 1, set *p* to 1  

--

.small-code[

```r
pairwise.t.test(pesticidedata$Yield, pesticidedata$Brand, p.adjust.method = "bonferroni")
```

```
## 
## 	Pairwise comparisons using t tests with pooled SD 
## 
## data:  pesticidedata$Yield and pesticidedata$Brand 
## 
##   Control A     B    
## A 1e-04   -     -    
## B 1e-06   1.000 -    
## C 1e-11   0.004 0.110
## 
## P value adjustment method: bonferroni
```
]

---
class: inverse

# reflection

#### At first, it can be confusing when a *p*-value is significant in one case (e.g., unadjusted) but not significant in another (e.g., Bonferroni)

- (especially if you're a grad student working on your thesis and you really *want* significant results)

--

#### If you find yourself in this situation, take a step back and think about a few things:

--

- What does the p-value measure? What is the risk when rejecting the null hypothesis? 

--

- When is falsely rejecting the null hypothesis (Type I error) most likely?

--

- What is so special about `\(\alpha = 0.05\)`?

---
class: center, middle, inverse

# tukey's hsd test

---
# john tukey

&lt;br/&gt;

&lt;img src="fig/John_Tukey.jpeg" width="246px" height="300px" style="display: block; margin: auto;" /&gt;

&lt;br/&gt;

&gt; The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data

---
# tukey's hsd test

&lt;br/&gt;

#### According to Tukey's Honestly Significant Difference test, two means ( `\(\bar{y}_i\)` and `\(\bar{y}_j\)`) are different if:

`$$\large |\bar{y}_i - \bar{y}_j | \geq  q_{1- \alpha,a,a(n-1)}\sqrt{\frac{MSW}{n}}$$`

&lt;br/&gt;

where `\(q\)` comes from the "Studentized Range Distribution"(see `qtukey` in `R`). MSW = mean squared error from the ANOVA table


---
# example


```r
fit.aov &lt;- aov(Yield ~ Brand, data = pesticidedata)
TukeyHSD(fit.aov)
```

```
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Yield ~ Brand, data = pesticidedata)
## 
## $Brand
##             diff     lwr   upr  p adj
## A-Control 3.1424  1.3174 4.967 0.0001
## B-Control 3.9403  2.1153 5.765 0.0000
## C-Control 5.6159  3.7909 7.441 0.0000
## B-A       0.7979 -1.0271 2.623 0.6639
## C-A       2.4735  0.6485 4.299 0.0034
## C-B       1.6756 -0.1495 3.501 0.0838
```

---
# *a posteriori* comparisons

--

- Bonferonni and Tukey's HSD are the most commonly used types of *a posteriori* comparisons - comparing all possible pairwise combinations only *after* a significant F-test

--

- There are many other types of *a posteriori* comparison, e.g. Fisher's LSD (see `?p.adjust` for even more)

--

- *A posteriori* comparisons decrease the risk of Type I error (but increase the risk of Type II error)

--

- By forcing the researcher to correct for all possible combinations, *a posteriori* comparisons often overly conservative 

--

- A better approach in many situations is to use *a priori* **contrasts**

---
class:center, inverse, middle

# *a priori* contrasts

---
# mussel size

&lt;table class="table table-striped table-hover table-condensed" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
&lt;tr&gt;&lt;th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="4"&gt;&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; "&gt;Watershed&lt;/div&gt;&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;"&gt; Twelvemile &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Chattooga &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Keowee &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; Coneross &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 16 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 18 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 28 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 14 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 25 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 22 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 20 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 22 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 24 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 11 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 17 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 16 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 20 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 17 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 13 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 26 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 27 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 15 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--
- Chattooga and Keowee are more forested  

- Coneross and Twelvemile are more agricultural

---
# anova results


.small-code[

```r
fit.mussel &lt;- lm(Length ~ Watershed, data = musseldata)
summary(fit.mussel)
```

```
## 
## Call:
## lm(formula = Length ~ Watershed, data = musseldata)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##   -5.4   -2.5   -0.2    3.0    4.6 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)            21.40       1.64   13.02  6.2e-10 ***
## WatershedConeross      -6.00       2.32   -2.58   0.0201 *  
## WatershedKeowee         2.80       2.32    1.20   0.2458    
## WatershedTwelvemile    -8.20       2.32   -3.53   0.0028 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.67 on 16 degrees of freedom
## Multiple R-squared:  0.645,	Adjusted R-squared:  0.579 
## F-statistic:  9.7 on 3 and 16 DF,  p-value: 0.000692
```
]

---
# pairwise comparisons


.small-code[

```r
pairwise.t.test(musseldata$Length, musseldata$Watershed, p.adjust.method = "bonferroni")
```

```
## 
## 	Pairwise comparisons using t tests with pooled SD 
## 
## data:  musseldata$Length and musseldata$Watershed 
## 
##            Chattooga Coneross Keowee
## Coneross   0.120     -        -     
## Keowee     1.000     0.010    -     
## Twelvemile 0.017     1.000    0.001 
## 
## P value adjustment method: bonferroni
```
]

---
# hypotheses

#### Instead of comparing all possible combinations, what if we are only interested in some specific comparisons?

1) Do the agricultural watersheds differ from one another?

2) Do the forested watersheds differ from one another?

--

#### Also, what if we are interested in *combinations* of treatments? 

3) Do mussels from forested watersheds differ from agricultural watersheds?

--

#### What are the advantages of focusing only on these specific questions?

---
# hypotheses as contrasts

#### Hypotheses

&lt;table class="table table-condensed" style="font-size: 16px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;  &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Comparisons &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; H0 to test &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Forested vs agricultural &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; \(\frac{\mu_T + \mu_{Co}}{2} - \frac{\mu_{Ch} + \mu_K}{2}=0\) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Twelvemile vs Coneross &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; \(\mu_{T} - \mu_{Ch} = 0\) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Chattooga vs Keowee &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; \(\mu_{Ch} - \mu_{K} = 0\) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

#### Linear combinations

&lt;table class="table table-condensed" style="font-size: 16px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; \((1/2)\mu_T - (1/2)\mu_{Ch} - (1/2)\mu_{K} + (1/2)\mu_{Co}\) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; \((1)\mu_T + (0)\mu_{Ch} + (0)\mu_{K} - (1)\mu_{Co}\) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; \((0)\mu_T + (1)\mu_{Ch} - (1)\mu_K + (0)\mu_{Co}\) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# are these contrasts orthogonal?

A set of linear combinations is called a set of orthogonal contrasts if the following conditions hold for all pairs of linear combinations:  

&lt;br/&gt;

--
Given

`$$\Large L_1 = a_1\mu_1 + a_2\mu_2 + ... + a_a\mu_a$$`
--

and

`$$\Large L_2 = b_1\mu_1 + b_2\mu_2 +...+ b_a\mu_a$$`
--

then `\(L_1\)` and `\(L_2\)` are orthogonal if:

`$$\large \sum_i a_i=0;\;\; \sum_i b_i=0; \;\;and \; \sum_i a_ib_i=0$$`

---
# back to the saw data

Returning to the question: "Does mussel size differ among forested and agricultural watersheds?":

`$$\large H_{0_1} = \frac{\mu_T + \mu_{Co}}{2} - \frac{\mu_{Ch} + \mu_{K}}{2} = 0$$`

--
Multiplying through by 2 gives:

`$$\large H_{0_1} = (\mu_{T} + \mu_{Co}) - (\mu_{Ch} + \mu_K) = 0$$`

--
Which can be written as:
`$$\large L1 = (1)\mu_T + (-1)\mu_{Ch} + (-1)\mu_K + (1)\mu_{Co}$$`
where the coefficients are `\(a_1 = 1\)`, `\(a_2 = -1\)`, `\(a_3 = -1\)`, and `\(a_4 = 1\)`

--

&gt; Note that it's easier to work with coefficients that are integers rather than fractions

---
# are the contrasts orthogonal?

--

#### Does each set of coefficients sum to 0?

- `\(\large L_1\)`: `\(\large \sum_i a = 1 - 1 - 1 + 1 = 0\)`


- `\(\large L_2\)`: `\(\large \sum_i a  = 1 + 0 + 0 - 1 = 0\)`


- `\(\large L_3\)`: `\(\large \sum_i a  = 0 + 1 - 1 + 0 = 0\)`

--

#### Do the products of pairs of coefficients sum to 0?

- For `\(\large L_1\)` and `\(\large L_2\)`: `\(\large (1)(1) + (-1)(0) + (-1)(0) + (1)(-1) = 0\)`

- For `\(\large L_1\)` and `\(\large L_3\)`: `\(\large (1)(0) + (-1)(1) + (-1)(-1) + (1)(0) = 0\)`

- For `\(\large L_2\)` and `\(\large L_3\)`: `\(\large (1)(0) + (0)(1) + (0)(-1) + (-1)(0) = 0\)`

---
# testing the null hypotheses

To obtain the sums of squares for each contrast, we use the general formula:

`$$\large SS_L =\frac{(\sum_i a_i T_i)^2}{n \sum_i a_i^2}$$`

where `\(\large  T_i\)` is the sum of observations in group `\(\large  i\)`, and `\(\large  a_i\)` is the corresponding coefficient for group `\(\large  i\)`  

--

For thefirst hypothesis we have:

$$ \large SS_{L_1} = \frac{(66-107-121+77)^2}{5(1 + 1 + 1 + 1)} = 361.2$$

---
# sums of squares for each contrast

For the second hypothesis we have: `\(\large L_2 = \mu_T + 0 + 0 - \mu_{Co}\)` with coefficients `\(\large a_i = (1, 0, 0,-1)\)`

`$$\large SS_{L_2} = \frac{(66 +0 +0 - 77)^2}{5(1 + 0 + 0 + 1)} = 12.1$$`

--

For the third hypothesis we have: `\(\large L_3 = 0 + \mu_B - \mu_C + 0\)` with coefficients `\(\large a_i = (0, 1,-1, 0)\)`

`$$\large SS_{L_3} = \frac{(0 + 107 - 121 + 0)^2}{5(0 + 1 + 1 + 0)} = 19.6$$`
---
# expanded anova table

For each contrast, each SS is divided by 1 d.f., and then divided by MSW

&lt;table class="table table-condensed" style="font-size: 16px; width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; Source &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; df &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; SS &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; MS &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; F &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; p &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; Among watersheds &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 393 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 131.0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.70 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.007 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; F vs Ag &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 361 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 361.0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 26.76 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9e-5 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; T vs Co &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 12.0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.90 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.36 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; Ch vs K &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 20 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 20.0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.45 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.25 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; Within &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 16 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 216 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 13.5 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

Notice that the Sums of Squares are partitioned according to hypotheses we are interested in, unlike in multiple comparison procedures.

---
# *a priori* contrasts

- Orthogonal contrasts are more powerful than multiple comparison procedures  

--

- They also require more thought and preparation (good things!)  

--

- There can be only `\(a - 1\)` comparisons  

--

- If the contrasts are not orthogonal, they can't be used to fully partition the Sums of Squares among groups  

--

- If the comparisons really represent more than 1 treatment variable, it will be better to use a factorial design. More on that later

---
# looking ahead

&lt;br/&gt;

### **Next time**: Multiple regression

&lt;br/&gt;

### **Reading**: [Fieberg chp. 3.2-3.5](https://statistics4ecologists-v1.netlify.app/matrixreg#introduction-to-multiple-regression)

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
